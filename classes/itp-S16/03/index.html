---
layout: default
title: ITP-NYU - Lecture 03, 4/7/2016
date: 4/7/2016
---

{% assign class = "itp-S16" %}
{% assign idx = 2 | plus: 0 %}
{% assign data = site.data.lectures[class][idx] %}

<h1><a href="/classes/itp-S16">ITP-NYU :: {{ page.date }}</a></h1>
<h1>{{data.title}}</h1>

{% include youtube_contents.html class=class index=idx width='400' %}


<h2>Class notes</h2>

<h3>News / admin</h3>
<ul>
	<li>office hours
		<ul>
			<li>official (M/T/W ?)</li>
			<li>unofficial at <a href="http://www.dbrslabs.com">DBRSLabs</a></li>
			<li>i want to meet everyone</li>
		</ul>
	</li>
	<li><a href="http://www.alt-ai.net/#exhibition">alt-ai exhibition</a></li>
</ul>

<h3>Critical issues</h3>
<ul>
	<li>Nick (<a href="https://docs.google.com/presentation/d/1DaALU1pyM0WMG2U8LNX2xNPQqYfHWNH2h743wdjLkGM/edit">Trolley problem</a>)</li>
	<li>Gene (<a href="http://home.cogeco.ca/~drheault/ee_readings/West/Descartes.pdf">Descartes on brutes</a>)</li>
	<li>bias, ownership, privacy <a href="http://us8.campaign-archive1.com/?u=bdb368b9a389b010c19dbcd54&id=f2e0882b79">(1)</a> <a href="https://www.reddit.com/r/science/comments/45k2pv/science_ama_series_we_study_how_intelligent/">(2)</a> <a href="http://www.nature.com/news/robotics-ethics-of-artificial-intelligence-1.17611">(3)</a> <a href="http://www.nature.com/news/machine-ethics-the-robot-s-dilemma-1.17881">(4)</a></li>
	<li><a href="http://socialmediacollective.org/reading-lists/critical-algorithm-studies/">Critical algorithm studies</a></li>
</ul>

<h3>Advanced Wekinator examples + Gesture recognition with Kinect + openFrameworks</h3>
<ul>
	<li>Wekinator pt. 2
		<ul>
			<li>Quick review</li>
			<li>inputs: Kinect, FaceOSC, bark/mfcc</li>
			<li><a href="https://github.com/genekogan/ofxAbletonLive/releases">AbletonOSC</a></li>
			<li><a href="https://github.com/genekogan/AudioUnitOSC">AudioUnitOSC</a></li>
			<li>max transpose visual</li>
		</ul>
	</li>	
	<li>Kinect gesture recognition
		<ul>
			<li>Pose detection (almost ready)</li>
			<li><a href="https://github.com/genekogan/Kinect2Gesture">Kinect2Gesture</a> (see <a href="https://vimeo.com/143963394">demo</a>)</li>
			<li><a href="https://github.com/nickgillian/ofxGrt">ofxGRT</a></li>
		</ul>
	</li>
</ul>

<h3>Introduction to convolutional neural networks</h3>
<ul>
	<li>Limitations of neural networks
		<ul>
			<li><a href="http://ml4a.github.io/dev/demos/cifar_confusion.html">CIFAR-10 accuracy</a></li>
			<li><b>Q:</b> how do normal neural nets deal with translation/stretch?</li>
		</ul>
	</li>
	<li>How convnets work
		<ul>
			<li>Convolution + pooling layers
				<ul>
					<li><a href="/dev/demos/demo_convolution.html">Convolution demo</a></li>
					<li><a href="/dev/demos/demo_convolution_all.html">Convolution demo 2 (all filters)</a></li>
				</ul>
			</li>
			<li>Classification demo</li>
			<li>Interpretation of n-1 layer</li>
			<li><a href="https://twitter.com/genekogan/status/651412627998937090">Convnets searches Instagram!</a></li>
		</ul>
	</li>
	<li><strike>Scientific applications of convnets</strike> (not in video)
		<ul>
			<li>Improved image classification</li>
			<li> -> localization, segmentation</li>
			<li>ensemble systems (annotation via RNN)</li>
		</ul>
	</li>
	<li>Artistic applications (<a href="/classes/itp-S16/04/">lecture 4</a>)
		<ul>
			<li>Visualization</li>
			<li>Deepdream, style transfer</li>
			<li>Visualization with t-SNE</li>
			<li>Transfer learning: Convnet -> Wekinator</li>
		</ul>
	</li>
</ul>

<h3><strike>Deep learning landscape</strike> (not in video)</h3>
<ul>
	<li>Main platforms
		<ul>
			<li>Caffe, Theano, Torch, TensorFlow</li>
			<li>Wrappers :)
				<ul>
					<li>Keras, tflearn</li>
					<li>Lasagne, nolearn</li>
				</ul>
			</li>
			<li><a href="http://www.openframeworks.cc">openFrameworks</a> support
				<ul>
					<li><a href="https://github.com/kylemcdonald/ofxCcv">ofxCcv</a></li>
					<li><a href="https://twitter.com/_mayfa/status/718079116705005569">real-time style transfer (@_mayfa)</a></li>
					<li><a href="https://github.com/memo/ofxMSATensorFlow">ofxTensorFlow</a></li>
				</ul>
			</li>
		</ul>		
	</li>
</ul>
